
## 강의

- NLP 도구 : PL, 자연어 관리/처리 도구, 토큰화, 트랜스포머, 허깅페이스
- N21 (classification) , N2N (token별 분류), N2M (번역, 대화)

- 모델링, 개발, 성능 개선, 서비스 배포 가능하도록!

### Overview
- NLP tasks : 재난 탐지, 코드 유사성 탐지, captioning 등...
- N21 : 모순파악, 연결 파악, 감정 분석, 주제 분석 등
- N2N : 토큰별 개체 분석, 향테소 분석
- N2M : 생성기가 필요. 답변 생성, 요약, captioning

- various benchmark dataset : 영어는 GLUE, 한국어는 KLUE 

### Pytorch Lightening
Process
- Data prep : 외부 데이터 다운 -> train, val, test로 분리 -> 텐서화 -> 배치화
- Model & Loss implementation : 문제에 맞는 모델과 loss 디자인
- iterate : epoch

PL
- high-level. Tensorflow의 추상화된 keras와 비슷한 포지션
- nn.Module 대신 pl.LighteningModule 상속해서 네트워크 구성.
- epoch 돌리는 코드도 경량화
- 분산처리, bottlenect profiler, hw support 등등 지원

- Torchmetrics : 여러 metric 제공, GPU 지원

### NL Data : Pandas
- series, dataframe : list, array, dict 등등으로 생성 가능
- df\[colname] 으로 col 지정, df.loc\[rowname], df.iloc\[indexname] 으로 특정 행/열 추출
- 조건 추출, 행/열 방향으로의 apply, 


### Tokenizer
개요
- 어떤 단위로 나눌 것인가? 
- 토큰을 어떻게 tensor화할것인가? : word2vec

방법
- char-based : length 길어짐
- word-based : space 단위, (한국어에 비효율적)
- subword-based : 의미있는 단어로 분절, OOV 해결 -> BPE


툴
KoNLPy : 형태소 분석, 태깅 라이브러리 있음
Sentencepiece : 여러 토큰화, 학습 가능
Tokenizer : 허깅페이스에서 제공, 이미 학습된 토크나이저 적용 가능


### Transformer
기존 NN의 문제점
- sequence data 처리 어려움, weight 매우 많음
- RNN으로도 long term capture 어려움, gradient exploding/vanishing

Attention
- 서로서로의 토큰의 반응 정도를 찾아서, 반응이 있는 것들을 모아 Blending.
- Q, K, V. 트랜스포머는 scaled dot을 사용.
- 자기가 가진 Query를 모든 key들과 반응시켜보고 -> 반응 정도만큼 value를 가져와서 합성.


### Huggingface

Transfer Learning
- pretraining -> fine-tuning pattern | ex. BERT
- 각자의 상황에 맞게 튜닝해서 사용

Huggingface
- 아키텍쳐의 재활용
- model param, embedding value, tokenizer 를 제공.
- 여러 util 제공 (beam search 등)


---

## Gemini Paper Review


### Abstract

- multimodal model인 Gemini를 소개합니다.
- audio, video, image, text understanding이 모두 가능.
- 여러 benchmark에서 30/32 SOTA, MMLU (human-expert performance) 에서도 모든 분야에서 개선된 성능.

### Intro
- image, audio, video, text 를 모두 학습시켰고, 다양한 domain에서 강력한 일반화 성능을 목표로 학습
- 이런 messy handwriting 이해 -> problem formulation -> problem과 solution을 수학 task로 변환 -> 각 단계에 대한 추론 -> 



### Model Architecture

- Transformer의 Decoder를 기반으로 구축, 구글의 전용 HW로 구조와 최적화를 해서 강화된 버전.
> Gemini models build on top of Transformer decoders (Vaswani et al., 2017) that are enhanced with improvements in architecture and model optimization to enable stable training at scale and optimized inference on Google’s Tensor Processing Units.


- 32,000 context length로 feed, multi-query attention으로 학습

- audio, visual input (natural image, chart, screenshot, PDF, video -> text와 image)

- Visual encoding은 Flamingo, CoCa, PaLI 에서 영감을 받았고

- Video는 이런 인풋을 large context window에서 sequence frame을 encoding해서 처리한다.
- 각 프레임은 동시에 주어지는 input의 audio나 text와 관련이 있을 것이고

- audio signal은 16,000Hz의 Universal Speech Model (USM) feature로 처리. -> 텍스트로 변환하면 없어져버리는 미묘한 뉘앙스 캡쳐 가능



### Training Infra
- TPU 가속기를 사용해서 여러 구글 데이터센터에서 학습. (전용 HW) 


### Dataset
- multimodal하고 multi-lingual한 데이터셋으로 학습.
- web documents, books, code, image, audio, video.
> Our pretraining dataset uses data from web documents, books, and code, and includes image, audio, and video data

- SentencePiece Tokenizer 사용. 토크나이저를 트레이닝 corpus 통째로 학습시키는 게 성능이 더 좋다.
> word encoding : vocab이 너무 커지고 없는 vocab은 말 못한다.
> subword encoding : 

- 토큰의 개수는 Hoffman et al을 따른다. -> Transformer LLM에서 최적의 model size와 token의 수 조사한 논문.
> the model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled.

- 휴리스틱 (손으로 ㅋㅋㅋ) & model-based classifier로 데이터 퀄리티 필터링 수행.
- Safety filtering & mitigation 수행 on harmful content
- 데이터 퀄리티가 critical.


### Evaluation

On Text :
- vs PaLM 2-L.
- MMLU, 수학, coding, 
- 다언어 수학과 요약
- Machine Translation (few shot setting) -> WMT 23
- Human Performance -> 작문, 멀티모달 이해, long-context understanding 등. 사람 앉혀놓고 블라인드 평가.
- Complex Reasoning System -> Alpha Code 2를 이겼다

On Multimodal :
- Image Understanding : 사물 인식, 캡셔닝, 질문과 대답 (VQAn2), 표 이해, 공간 이해
- 다언어로도 가능
- 코드 재배치 -> plot recognitoin, 그래픽을 코드로 변환, 지시문 이해와 수행, 추상적 사고 (어떤 게 origianl에 있어야 하는지)

On Video : 
- 비디오 캡셔닝, 요리 비디오 캡셔닝, 보고 질문에 답하시오 등.
- temporarily-realted sequence of frames.
- 유튜브 데이터셋

Image Gen :
- 자연어 descriptoion이 없어도 작동.
- 이미지나 비디오, 텍스트를 보여주는 것으로 (few-shot) prompting이 됨.

On Audio :
- speech translation, speech recognition 등.
- vs USM, Whisper


### Deployment

- 평가 -> mitigation 반복하다가 depoly한다고.
- impact assessment도 하고, 모델 정책도 만들고 (child safety, hate speech, factural accuracy, harassment...)
- Reinforcement Learning through Human Feedback.



### Discussion
- 다양한 분야에서 sota 달성.
- sota보다도 여러가지 할 수 있어서 신난다
- 하지만 100% 신뢰하진 말어라.
- 지성과 과학, 인류의 발전을 위해서 더 나아가겠다.


---

## 멘토링

Overview
- 처음부터 끝까지의 프로세스를 다 경험해보면 좋을 것이다.
- 데이터 분석 -> 모델 선정
- 1주일정도는 각자 풀 파이프라인을 만들어보고, 2주차때 공유하면서 합을 맞춰보자.
- 자기만의 스타일이 있는 템플릿을 만들어두면 빠르게 할 수 있다. 

Pytorch Lightening
- 필수 요소 4가지 : torch.utils.data.Dataset / pl.Trainer / pl.LighteningModuel / pl.LighteningDataModule
- seed_everything이라는 함수도 편하게 사용 가능
-  Dataloader에서 사용하는 함수는 train / val / test / predict 4가지를 해줌
- 마찬가지로 module 정의할 때도 그 내부에 train / val / test / predict 만들어주고, optm도 만들어줌


베이스라인은 통일하는게 좋다. 실험 결과를 신뢰할 수 있기 때문에
model.eval() 이나 model.train() 

차원 변환같은 경우에는 먼저 그림이나 화이트보드로 기록하고 시작함.


Ray나 WanDB, TensorBoard를 이용해서 튜닝이나 학습에 대한 상황을 기록해서 시각화해서 공유해보기


---

## Lev 1 프로젝트 관련

- df -H 로 데이터 쓸 수 있는 공간 체크하기.

팀별 Wrapup :
- 개인의 역할/역량/성과가 드러나도록 작성.
- 프로젝트 개요, 팀 구성과 역할, 수행 절차 및 방법, 수행 결과, 자체 평가 의견 포함.
- 권장량 5-6페이지, 개인 회고 인당 1장.


#### 데이터 측면
텍스트 전처리 : 문법 교정, outlier 걸러내기, data imbalance는 유의어 집합으로 교체.
- 맞춤범 검사 전처리
- 불용어 처리

#### 모델 측면
STS task에 보통 무엇을 쓰는지?

#### My Idea
contrastive learning에 사용할 수 있도록 binary label을 활용해서 loss function을 디자인?
BLEUscore의 유사도를 첨가해보기?


---

## 깃허브  

### GitFlow : Branch의 종류

#### main
- release 기준
- main에는 직접 commit하면 안됨. 오직 merge from develop, release
- main은 자동으로 테스트 돌리고 하는게 연결되어 있음
- hotfix의 경우 예외적으로 merge 가능.
- **main에 직접 commit하고 push하면 안됨!**

#### develop
- 개발의 중심
- 여러 사람이 만지기 때문에, issue나 feature를 따서 별도로 작업

#### feature
- 실제로 각각의 기능을 구현하는 branch.
- develop에서 branch 내서 구현하고 commit하고, 다시 develop으로 merge
- 브랜치명에 feat, refactor, fix, docs와 같은 prefix 사용

#### release
- 실제 배포 준비하는 branch.
- release가 결정되면 develop에서 떼어내어 QA나 bugfix를 진행.
- bugfix가 진행되면, develop을 다시 최신화.  

#### hotfix
- main 긴급

### GitHub Flow
- branch를 적당히 나눠서 목적에 맞게 관리하면 됨.
- main branch에 commit, push는 엄격하게 수행. (바로 서비스로 연결되기도 함)