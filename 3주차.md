
## DL
### 1장 Historical Review
- 프로그래밍, 수학, 동향.
- `데이터`, `모델`, `loss`, `파라미터 최적화 알고리즘` 을 결정해야 함.

### 2장 NN
- w = w - a * d Loss / d w
- 여기에서 학습률은 보폭, gradient는 방향 (이자 보폭이기도 함)
- 선형결합의 반복만으로는 행렬 n개의 곱 (여전히 선형변환) -> 따라서 activation function으로 non-linerarity 확보.
- loss function에 대한 정의와 pros, cons 를 이해하고 목적에 맞게 사용해야 함
> MSE는 outlier에 맞추려다가 일반화 성능을 말아먹을 수도 있음

### 3장 Optimization
- generalization : train / test set 모두에서 좋은 결과를 내는 것.
- Cross - validation (k-fold) : train/ test set을 돌아가면서 사용하는 것
- Bias-Variance tradeoff : Cost function을 수식적으로 분해하면 bias^, variance, noise로 구분됨. 따라서 둘 다 줄일 수 없다.
- Bootstrapping ; random sampling with replacement. 
> Bagging : bootstrapping으로 여러 모델을 만들어 ensemble (random forest)
> Boosting : weak learner를 sequentially 결합해 strong model을 만듬

- Gradient Discent : 방향과 보폭을 구해 local minimum으로 weight update
- Stochastic (한번에 1개씩 사용) / Mini-batch (n개씩 사용) / Batch (전체 사용) -> batch size가 작을수록 generalization performance가 좋아짐.

- SGD : too lr dependent.
- Momentum : gradient에 momentum을 주어서 이전 방향으로 유지되도록
- Nesterov : Gradient를 lookahead함. 미리 갈 곳을 한번 예측해서 거기서의 gradient와 결합해 gradient 계산.
- AdaGrad : lr을 점점 작게 만들어줌 -> 학습이 늦어지는 문제
- RMSprop : 이전까지의 lr에 대한 가중치를 부여해, 그 값을 나눔 (lr이 무한정 작아지지는 않음)
- Ada + Momentum (ADAM) : adaptive와 momentum을 합침.

#### Regularization (how to prevent overfitting)
- Early Stopping : training erorr 올라가는 시점에서 정지
- Parameter Norm Penalty : param 자체의 숫자적 크기를 줄이도록 loss function에 포함 (부드러운 함수로)
- Data Augmentation ; 크기, 방향, 회전 등
- Noise Robustness ; 노이즈 추가
- Label Smoothing ; 고양이 0.5, 강아지 0.5 등으로 이미지와 레이블 모두 섞어버리기. 실제로 성능이 올라감.
- Dropout : 학습 단계에서 일부 weight를 0으로 만들기.
- Batch Norm : layer를 통과할 때마다 정규화. 깊어질수록 잘 작동 

### 4장 CNN
이미지에서의 convolution은 필터링 작용.

kernal이 2차원이든, 3차원이든, 원본 이미지에 들어가는 그 사이즈 하나대로 1개의 값만이 나온다.
- convolution & pooling : feature extraction의 역할
- full connected layer : decision making의 역할

- 파라미터의 숫자가 데이터에 비해 너무 늘어나면 일반화 성능이 떨어짐.
- 그래서 Full connected layer보다 conv layer를 쌓으면서 weight 개수를 줄이도록 발전중.

==CNN에서 param 계산하는 방법 복습해두기==

- 1 * 1 conv는 dimension reduction 역할을 수행 -> bottleneck architecture

### 5장 Modern CNN
AlexNet
- 5개의 conv, 3개의 dense
- ReLU를 사용, Data Augmentation, Dropout, GPU implementation

VGGNet
- 3 * 3 kernal만 사용해서 depth를 깊게 만듬 (파라미터 수를 줄임)
- 1 * 1 kernal로 dimension reduction

GoogleNet
- inception block 활용 (여러 conv를 거친 후 concat) : 채널을 줄이는 것 (차원축소) param 수를 크게 줄임.

ResNet
- skip connection을 통해 residual (잔차) 만을 학습. output에다 원본 x를 더해줌.
- 3 * 3 conv 적용 전에 channel 수를 줄이고, 적용 후에 다시 늘려주는 bottleneck 활용 (param 줄이기 위해)

DenseNet
- ResNet처럼 output과 x를 그대로 더하지 말고, 전 단계의 값을 concat만 해줌.
- 다만 이러면 기하급수적으로 채널 수가 커져서, 중간중간에 채널을 줄여주는 1 * 1 conv를 반복.


==왜 bottleneck을 하는지 잘 설명해주셔서 좋았다. 이렇게 하면 param 개수가 줄어든다 -> 오버피팅 회피 가능==

CNN 시각화 관련 재미난 사이트
https://poloclub.github.io/cnn-explainer/

### 6장 CV applications
Semantic Segmentation
- 픽셀마다의 테두리 찾아내기
- 쭉 펴서 Full Connected layer로 원하는 개수의 pixel대로 output 만들기 vs 컨볼루션화 (param 수는 같음)
- full convolution network는 input size에 상관없이 작동하며, heatmap을 그려볼 수 있다!

이렇게 하려면 upscaling 방법이 필요한데.. 이 중 하나로 deconvolution이 있음.
- Deconvolution : dimension을 늘릴 수 있음

Detection
- R-CNN : 이미지를 특정 알고리즘에 따라 잘라 모두 CNN에 투입해 SVM으로 분류.
- SPPNet : CNN은 한번만 투과하고, subtensor를 여러개 뽑아서 SVM으로 분류 (순서만 바꿈)
- Fast/ Faster R-CNN : bounding box를 뽑는 과정을 neural network로 처리
- YOLO : labeling과 동시에 bounding box를 처리. 

==bounding box 예측 방법과 그에 따른 구조 등등이 버전과 이름에 차이가 있다.==


### 7장 RNN

input의 길이를 미리 알 수 없고, 다음 데이터가 이전에 dependent.
- 초기 RNN : hidden state weight가 있음, long dependency 표현 어려움, long input은 gradient 소실.

LSTM
- Cell state는 conveyer belt처럼 흘러가는데, Gate를 통해서 어떤 정보를 올리고 내릴지를 결정. 
- Forget gate : 이전 cell state와 현재 x. 어떤 정보를 버릴지 결정.
- Input Gate : 현재 x 중 어떤 것을 올릴지 결정

Gated Recurrent Unit (GRU)
- 2개의 gate (reset, update)만으로 구현. 파라미터 줄어서.

### 8장 Transformer

구조
- encoder / decoder stack.

encoder에서 어떻게 sequence가 한번에 처리되는지.
- RNN처럼 계속 돌지 않고, positional embedding을 하고, self-attention을 함으로써 서로간의 long-term 관계 파악.
- multi-head로 처리하고, 이걸 concat해서 다음으로 넘김
- 이걸 stack한 횟수만큼 반복.

왜 잘 되는지?
- 자신이 encoding되는 방식이 주변 값들에 영향을 받는다. 기존 dense layer들은 weight에만 영향을 받았음.
- 그래서 주변간의 관계를 많이 표현함.

트랜스포머는 N개의 단어가 있으면 N * N 의 attention map을 만들어야 한다. 물리적 메모리의 한계. 

구현상의 차이점
- ==실제 코드에서 구현되는 구현체는 multi-head를 할 때 동일한 10개를 사용하는 게 아니라, embedding vector의 차원을 multi-head의 개수만큼 쪼개서, 나중에 concat할 때 원래 차원으로 돌아오도록 만든다!== 
- 즉, 100dim에 embedding되어있고, 10개의 head로 쪼개면, 10 dim짜리 10개로 쪼개서 넣고, 나중에 concat한다.

Positional Encoding
- 순서에 대한 정보를 넣어주기 위해 특정한 지문을 만들어 벡터에 더해줌.

decoder가 어떻게 생성하는지
- 인코더에서 생성한 Key와 Value matrix를 넘겨주어, decoder에서는 query만 할 수 있도록

학습 방법
- word masking으로 다음을 추론할 수 있게 unsupervised learning.

최종 단계의 vector를 vocab_size의 dim으로 투사한 후 softmax해 단어를 추론.

ViT
-  이미지를 잘라 사용해도 서로의 관계를 파악하는데 유용하다.

### 9장 GAN

- 동전이 n개 있다면 앞/뒤의 상태를 나타내는 sequence의 종류는 2^n개.
- Independence Assumption : n개
- Markov Assumption : 이전의 상태에만 영향을 받는다. 2n-1 (Autoregressive model)

AutoRegressive Model 자가회귀 모델
- chain rule을 통해 쪼갠 것을 conditinal independence 가정으로 markovian하게 쪼갠다.
- NADE (Neural Autoregressive Density Estimator) : given input의 explicit density를 구하는 모델.

Maximum Liklihood Learning
- 샘플이 있을 확률의 합을 최대화하는 파라미터를 최적화하는 학습.
- KL-divergence는 두 확률분포 사이의 거리. Cross Entropy를 최소화하는 방향으로.
- overfitting 위험이 있어 강한 regularization을 사용. model space를 줄임.
- gaussian으로 시도는 많이 했지만 image generation은 먼 이야기였음.

Latent Variable Model (Autoencoder)
- encoder - decoder를 통한 생성 모델 학습
- Variational inference ; Bayesian inference에서, 찾을 수 없는 posterior dist를 찾기 위해 var를 추정.
- ELBO를 최대화, variational gap은 조절할 수 없기 때문.
- Autoencoder의 loss를 최소화함과 동시에, latent vector가 prior dist와 비슷하게 되는 param 찾기.
- 여러 한계가 있음. 특히 KL divergence를 isotropic한 gaussian으로만 추정할 수 있었음.

Generative Adversarial Network
- 2개의 네트워크가 각각 generate, discrimmination. 
- 각각이 갖는 Loss function은 맞는 것은 작게, 틀린 것은 크게 penalty를 주도록 설계.
- 이를 풀어보면 discrimminator의 최적은 Jenson-Shannon Divergence 형태로 나옴.

Diffusion Model
- noise로부터 두 가지 작업을 반복해 생성.
- forward (diffusion) ; noise를 추가.
- reverse : denoise. 모델은 이 과정을 학습하게 됨.


---
## Data Viz

###  1장 Matplotlib

시각화의 요소
목적, 독자, 데이터, 스토리, 방법, 디자인

데이터의 종류
1) 정형 데이터 : csv. 통계적 특성 (분표, feature간 관계, 평균 등)
2) 시계열 데이터 (Time series) : 추세, 계절성, 주기성
3) 지리적 데이터 : 거리, 경로, 분포 등 확인 가능
4) 관계 데이터 : 객체간 관계를 시각화. node와 link. 크기나 색, 수 등으로 가중치 표현
5) 계층 데이터 : 네트워크나 트리 구조로 구분

데이터의 종류
- 수치형 (연속 / 이산)
- 범주형 (명목 : 단순 타입 / 순서 : 타입의 우열 있음)

시각화의 구성
- mark : 점, 선, 면. 
- channel : mark의 배치 요인 (모양, 길이, 방향, 기울기, 위치 등)

전주의적 속성
- 자연적으로 바로 알아챌 수 있는 요인들. (혼자만 크기나 방향, 색이 다른 경우.)
- 이를 통해 원하는 point 강조 가능

###  2장 Bar, Line, Scatter

Bar Plot
- Multiple bar plot (여러 개) : 각각의 분포를 파악하기 좋음
- Stacked bar plot (쌓아서) : 2종만 있으면 positive / negative로 표현해도 됨. (percentage bar로 해도 )
- overlapped bar plot (겹쳐서) : alpha값 조절하기
- Grouped Bar plot (그룹화해서) : 가장 좋은 방식이지만, matplot에서 구현이 까다로움 (그룹이 3개 이하일 때 추천)

Bar Plot Tip.
- 값을 표현하는 데 드는 잉크 양은 그에 비례해야 한다 = 1을 표현할 때는 1만큼의 잉크가, 5일 때는 5의 잉크가.
- 데이터의 종류에 따라 보기 좋게 정렬해서 시각화할 것
- 공간을 넉넉하게 활용할 것 (x, y limit과, spine, gap, legend, margin 등등..)
- 되도록 단순한 형태로 그릴 것

Line Plot
- 연속적인 변화를 시각화. 0부터 시작할 필요는 없음
- 색상 / 마커 / 선의 종류 에 따라 효과를 다르게 할 수 있음

Line Plot tip
- noise를 조금 제거해야 보기 좋을 수도 있다.  
- x축의 간격을 균등하게, 좁게-넓게 하느냐에 따라 인식이 크게 달라진다. (떡상과 떡락)
- 심한 smoothing 은 오해를 불러일으킬 수 있음.
- legend() 대신에 라인 끝에 라벨을 붙이는게 시각적으로 좋을 수도.
- Min/Max 정보를 포함하면 더 보기 좋음.

Scatter Plot
- 두 feature 간의 상관관계를 알기 위해
- 또는 군집clustering, 두 값 간의 차이, outlier 등등을 확인 가능
- 색, 모양, 크기로 비교 가능 (sentosa)
- 추세선과 uncertainity를 활용 가능 (regression)

Scatter Plot Tip
- 점이 많아지면 파악하기가 힘들다 -> 투명도 조정, 2차원 히트맵(구획화), contour plot 등으로 표현 가능
- 색을 다르게 해서 종류 표현 / 크기를 다르게 하면 bubble chart 로 활용 가능
- 그리드와는 상성이 나쁘다.

###  3장 Chart Elements

#### Text 요소의 사용
- title, legend, tick, annotation 등..
```python
fig.suptitle("") # 슈퍼타이틀
fig.legend()     # 레전드
ax.set_title()   # 부제
ax.set_xlabel(), ax.set_ylabel() # 레이블
```

- 텍스트 속성 : font, size, style, bold, italic 
- 비텍스트 : color, linespacing, backgroundcolor, alpha, zorder, visible 등
- 정렬 : ha, va, rotation


#### Color의 사용
- 디자인적이기도 하지만 강조 표현도 가능. 가급적 기존 정보에 익숙하도록 (기온 등등..)
- Categorical한건 전부 다르게 / 연속값은 gradient로 / one color는 분포를 보는 데 유리
- Contrast : 명도 / 색상 / 채도 / 보색
- HSL (Hue색조, Saturate채도, Lightness명도)

#### Facet의 사용 (분할)
```python
fig, axes = plt.subplots(2, 3, figsize = (10,6))
```
- 2차원이 되면 flatten()으로 axes를 1차원으로 눕힐 수 있음 (for문 사용 가능)
- `aspect` : 화면비
- add_gridspec() : 3 * 3 으로 만들어놓고 인덱싱으로 병합해 서브플롯팅 가능.

#### 기타 팁
Grid의 사용
- color, zorder, axis
- x, y축에 평행하지 않은 다양한 그리드를 적재적소에 사용 가능 (동심원, 원점의 다른 기울기 등)

선, 면 추가
- line : 상한, 하한, 추세선
- area : 구간 grouping (axvspan, axhspan)
- spine 관련 : set_visible() / set_linewidth() / set_position() 

테마 추가
- rcParams로 기본 세팅 설정 바꿀 수 있음.
- seaborn이나, ggplot 스타일도 바꿀 수 있음.

---
### 멘토링
- 문제 정의도 중요하고, 팀원과 어휘 사용에 혼동이 없는지도 싱크로하면 좋음.
- 그런 이유에서 입사할 때 커뮤 능력을 물어보는건데, 거창한 게 없어도 정말 커뮤가 되는지 실제적인 예시
- 모델의 메트릭이 좋다고 단순히 넘어가지 말고, 메트릭의 정의나 측면 차원에서, 메트릭이 왜 잘 나왔는지, 잘 안나왔는지 등등 구체적인 사례들을 분석해보는 게 중요함. 그런걸 자기소개나 경력에 쓰면 쓸 말도 많을 거임. (나 ROGUE나 BLEU score 차원에서는 잘 나왔는데 의미상으로 틀린 경우.. 또는 unk 토큰이 너무 많이 나와서 틀렸다는 식의 통계를 얻으면 모델을 수정할 insight를 얻을 수 있음.)
- 프로젝트는 미리 기획해두기. 4주가 주어지는데 그 안에 기획부터 시작하려면 늦음 . 미리 구체화해보기

- 버전 관리나 회의 기록 등등.. 별도의 툴을 사용하시는지. -> Jira

---

### 추가 공부


- [ ] self-attention 손으로 계산해보기. QKV 차원 맞는게 약간 이해가 안감..
- [ ] CNN에서 파라미터 개수 구하기 직접 해보기.
- [ ] CNN의 XAI 테크닉 maxpooling 시각화 방법에 대해서 공부해보기.
- [ ] 트랜스포머 구현체 허깅페이스에서 받아서 확인해보기.
- [ ] 파이토치 프로젝트 주석 달아서 해보기.
- [ ] segmentation YOLO 원리 좀더 공부해보기.
- [ ] MLE에 대해서 좀더 이해해보기.. 반드시 확률분포에 대한 가정이 필요한가?
- [ ] 직접 뉴럴네트워크 구현해보기. 완전히 0에서부터.
- [ ] XGBoost 사용해보기
- [ ] self-어텐션의 역전파
- [ ] Diffusion model 공부


---

### 팀 회고

#### 잘한점
- 데이콘 데이터 분석 결과를 공유하면서 서로 다른 측면에서 바라본 특성들을 파악할 수 있어서 좋았음
- 확실히 아침에 같이 스크럼으로 학습을 시작하는 게 안 늘어지고 좋은 거 같다고 느낌.
- 활용성이 높은 시각화에 대해 체계적으로 배우는 점. 데이콘 하면서 바로 적용해볼 수 있어서 좋음.


#### 아쉬운 점
- 더 부지런하게 하고싶다는 생각이 듬. 시간을 효율적으로 활용할 방법
- 멘토링 일정을 잊어버려서, 비상 연락망 공유함.


#### 시도할 점
- 데이콘 마무리,
- BERT 논문
- Diffusion의 denoising 이론 공부 (with VAE)
- XAI, GRAD-CAM, max-pooling
- segmentation YOLO 원리
- MLE 관련 공부 (모든 확률분포에 대해 성립 가능한지?)
- huggingface Transformer 구현체의 소스코드 분석 (self-attention 차원과 역전파 등)


#### 공부 키워드
- Adam optimizer
- segmentation bounding box 예측 방식
- CNN 파라미터 계산하는 방법
- 1D conv의 dimension reduction 효과 


#### 개인 회고
ML 기본 공부들을 다루면서 간단하게 넘어가는 것들이 많은데 공부 줄기를 뻗어갈만한 지점이 많다.
마스터님들, 멘토분들의 모든 조언에서 공통적으로 알게 되는 것은 적극적인 커뮤니티 활동이 많은 도움이 된다는 것.
토론하고 가르치고, 질문하고 대답하는 것이 학습에 큰 도움이 된다는 걸 새삼 다시 느낀다.