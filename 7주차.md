
## 강의 정리

### N21
**Sentence Classification**
- 감정 분류 : 4개의 multi-class
- 정답의 표현 : one-hot (일관성이 중요)
- input -> Net forward -> output layer softmax -> loss backpropagation
- Loss : MSE (regression), L2, L1, CrossEntropy (classification)... 
- Loss를 미분해 방향을 찾아, weight update.

**Transformer의 활용**
- 입력을 tokenization -> 각 token에 대해 encoding 수행 -> 최종 output vector를 mapping (fc layer)
- !!padding된 부분은 atetntion_mask에서 0으로 표기되어야 함!!
- token_type_ids는 문장 구분을 위해 삽입

### N2N
**sequence labeling**
- PoS (part of speech 형태소 분석), NER (named entitiy recognition; 개체명 추출)
- huggingface의 TokenClassification으로 훈련 가능.
- subword나 char 단위로 분리. 
- 정답 ref는 IO / BIO / BIOES 방식으로 레이블링 (토큰화 방식에 따라 다름)

**Loss** 
- Cross entropy : ignore_index는 관습적으로 -100으로 설정되어있음. 특정 label에 가중치를 두고 loss 계산도 가능.

**Metric**
- Recall, Precision, F1 score, Acc 등으로 classification의 정확도를 계산
- Macro는 모든 label의 평균, micro는 label 상관없이 전체 데이터에 대한 결과

### N2M
**생성 task**
- 번역, 질의응답, captioning 생성 등 
- encoder, decoder 두가지 동시에 활용됨 (encoer는 vector 표현 학습, decoder는 이를 활용)
- RNN -> LSTM -> Seq2Seq -> Attention -> Transformer

- encoder only : 정보를 양방향으로 취합 (분류 문제) -> masked language modeling, NSP
- decoder only : 단방향으로 취합 (주로 생성)

- BART : BERT+GPT (손상된 문장으로 학습)
- T5 : text로만 구성된 학습

Decoding 방식
- Greedy : 가장 높은 확률만 선택
- Beam : top k의 후보들 진행
- N-gram penalty : 동일한 단어가 N개 이상 생성되지 못하게 함.
- 허깅페이스 안에 generation_utils 안에서 구현체 활용할 것.

### Prediction Service
FastAPI 백엔드
- 간단, DB 연결 가능, 속도와 안정성
- 서버에서 ckpt를 올려두고, 외부에서 translation 요청이 들어올 경우 JsonResponse로 예측 결과 반환.

Streamlit 프론트엔드
- python으로 웹뷰 지원. pandas와 잘 연동됨.
- Markdown을 바로 표시 가능.
 
---

### 마스터클래스
여러 NLP 테크닉

- 역번역 (backtranslation) : 한->영->한
- task 추가
- 통계 모델 생성 :  구성 요소만 살짝 변경


---

### 멘토링

이번주는 git lfs로 허깅페이스에서 track
Poetry

앙상블 테크닉
- 각자 잘 맞추는 분포를 보기.
- 모델 12개를 쓴다면 4개는 0~1 사이에 특화된 애. 4개는 1-2사이에 특화된 애.  2-3 사이에 특화된 애 4개.
- 이런 식으로 모든 걸 잘하는것보다도 뭐에 특화된 애들 여럿을 붙이는것도 좋다.


다음주는 도커, FASTAPI랑 SteamLit, 도커로 이미지화해보기



---
### 주간 회고


**잘한거**
- 서버 세팅, 가상 환경 위에서 모델 운영, wandb로 metric 모니터링 등 다양한 경험
- 특히 contrastive learning에 대해 모델과 데이터셋, 구현 등등 다양하게 공부할 수 있었음

**아쉬운거**
- 주로 시도했던 방향이 모델 성능 개선에 크게 기여하지 못해 아쉬웠음. 
- 서버 및 가상 환경 세팅에 난항을 겪음.
- 깃허브 활용이 다소 부족했다고 생각됨.

**시도할점**
- package dependency나 충돌 상황에 대한 troubleshooting에 더 익혀두고 싶음.
- 모델에 대해 더 자세히 볼 시간이 있어서 어텐션을 시각화하는 등의 XAI 해석을 적용했으면 어땠을까?

**공부 키워드**
- Contrastive Leraning
- XAI on Transformer
- Conda, package dependency setting

**개인 회고**
- 실제 프로젝트를 진행하면서 서버 관리, 가상환경 세팅, metric 모니터링, 모델 이론 공부 및 가설검증 등 다양한 경험을 할 수 있어서 좋았다.
- 버전 관리와 트라이 기록을 공유하는 방법의 중요성을 절감했다. 나만의 방식으로 정리할 때와는 달리, 팀원 모두가 알아볼 수 있는 템플릿을 합의해야 하고, 이를 주기적으로 업데이트/관리해야 한다.
- contrastive learning과 관련하여 이론과 코드를 이해하고 적용하는데 시간이 많이 소요되어 양질의 데이터셋을 생성할 시간이 부족했던 점이 아쉬웠다. 추후에 더 적용해보고 싶음.
